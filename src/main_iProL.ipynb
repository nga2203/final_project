{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "『PBC note』Longformer_base_Net相比base，没有LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Project\\DNA\\iProL\\src\\feature_extraction\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import config_iProL as config\n",
    "from dataset import get_datasets, get_cv_dataloader_list\n",
    "from dataset import get_excel, get_complete_data\n",
    "from module import Longformer_base_Net\n",
    "from tools import check_result_dir\n",
    "from tools_fit import model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\DNA\\iProL\\src\\dataset.py:81: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset_level[\"Con_level\"] = dataset_level[\"Con_level\"].replace([\"Strong\", \"Weak\"], [1, 0])\n",
      "d:\\Project\\DNA\\iProL\\src\\dataset.py:85: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset_type[\"Sigma\"] = dataset_type[\"Sigma\"].replace(sigma_list, label_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBC[ProL] --- kmer = 2\n",
      "train len: 3382 test len: 3382\n",
      "PBC[ProL] --- kmer = 2\n",
      "train len: 3382 test len: 3382\n"
     ]
    }
   ],
   "source": [
    "sheet = get_excel(version='', sheet_name='dataset')\n",
    "complete_data = get_complete_data(sheet)\n",
    "\n",
    "dataset_identify, _, _ = get_datasets(complete_data)\n",
    "\n",
    "identify_dataset_list, identify_loader_list = get_cv_dataloader_list(config, dataset_identify, \"Pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filterwarnings(\"ignore\")\n",
    "# torch.manual_seed(0)\n",
    "# torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ex result dir d:\\Project\\DNA\\iProL\\src\\../result/longformer/_train[kmer2_bs64_lr0.0005_epoch25]_pm[astFalse_nftTrue_levelbase]\\ProL_1216232630_Pro\\1 has been created!\n",
      ">>>>>>>>>>『CV START』[2/1-->lr:[0.0005]]>>>>>>>>>>>>\n",
      ">>>>>>>>>>『CV START』[2/1]>>>>>>>>>>>>\n",
      "『Computer device』nvidia:ProL\n",
      "『dataset』kmer: 2, cv: 2\n",
      "『train config』epochs: 25, lr: 0.0005, batch_size: 64, device: cuda\n",
      "『pre-model config [True]』add_special_tokens: False, not_fine_tuning: True, model_name: longformer-base-4096\n",
      "『ex result config』ex_result_dir: d:\\Project\\DNA\\iProL\\src\\../result/longformer/_train[kmer2_bs64_lr0.0005_epoch25]_pm[astFalse_nftTrue_levelbase]\\ProL_1216232630_Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded to be a multiple of `config.attention_window`: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 [53/53] total_loss = 0.607885608695588 lr = 0.0005, total=3382, TP=1197, TN=1160, FP=531, FN=494; precision=0.693, recall=0.708, Sn=0.708, Sp=0.686\n",
      "roc_auc: (test=0.764) average_precision: (test=0.758) accuracy: (test=0.697) matthews_corrcoef: (test=0.394) f1: (test=0.700) \n",
      "epoch 1 [53/53] total_loss = 0.5985800736355331 total=3382, TP=1532, TN=926, FP=765, FN=159; precision=0.667, recall=0.906, Sn=0.906, Sp=0.548\n",
      "roc_auc: (test=0.851) average_precision: (test=0.852) accuracy: (test=0.727) matthews_corrcoef: (test=0.486) f1: (test=0.768) \n",
      "\n",
      "epoch 2 [53/53] total_loss = 0.505197323155853 lr = 0.0005, total=3382, TP=1263, TN=1326, FP=365, FN=428; precision=0.776, recall=0.747, Sn=0.747, Sp=0.784\n",
      "roc_auc: (test=0.833) average_precision: (test=0.834) accuracy: (test=0.766) matthews_corrcoef: (test=0.531) f1: (test=0.761) \n",
      "epoch 2 [53/53] total_loss = 0.5339869733126659 total=3382, TP=1191, TN=1473, FP=218, FN=500; precision=0.845, recall=0.704, Sn=0.704, Sp=0.871\n",
      "roc_auc: (test=0.861) average_precision: (test=0.862) accuracy: (test=0.788) matthews_corrcoef: (test=0.584) f1: (test=0.768) \n",
      "\n",
      "epoch 3 [53/53] total_loss = 0.48367059399496837 lr = 0.0005, total=3382, TP=1241, TN=1379, FP=312, FN=450; precision=0.799, recall=0.734, Sn=0.734, Sp=0.815\n",
      "roc_auc: (test=0.848) average_precision: (test=0.850) accuracy: (test=0.775) matthews_corrcoef: (test=0.551) f1: (test=0.765) \n",
      "epoch 3 [53/53] total_loss = 0.5356748891326616 total=3382, TP=1410, TN=1266, FP=425, FN=281; precision=0.768, recall=0.834, Sn=0.834, Sp=0.749\n",
      "roc_auc: (test=0.864) average_precision: (test=0.866) accuracy: (test=0.791) matthews_corrcoef: (test=0.585) f1: (test=0.800) \n",
      "\n",
      "epoch 4 [53/53] total_loss = 0.47978836916527656 lr = 0.0005, total=3382, TP=1263, TN=1370, FP=321, FN=428; precision=0.797, recall=0.747, Sn=0.747, Sp=0.810\n",
      "roc_auc: (test=0.848) average_precision: (test=0.854) accuracy: (test=0.779) matthews_corrcoef: (test=0.558) f1: (test=0.771) \n",
      "epoch 4 [53/53] total_loss = 0.5182819169647289 total=3382, TP=1334, TN=1353, FP=338, FN=357; precision=0.798, recall=0.789, Sn=0.789, Sp=0.800\n",
      "roc_auc: (test=0.864) average_precision: (test=0.867) accuracy: (test=0.795) matthews_corrcoef: (test=0.589) f1: (test=0.793) \n",
      "\n",
      "epoch 5 [53/53] total_loss = 0.47827176890283263 lr = 0.0005, total=3382, TP=1280, TN=1376, FP=315, FN=411; precision=0.803, recall=0.757, Sn=0.757, Sp=0.814\n",
      "roc_auc: (test=0.850) average_precision: (test=0.853) accuracy: (test=0.785) matthews_corrcoef: (test=0.572) f1: (test=0.779) \n",
      "epoch 5 [53/53] total_loss = 0.5158009635952284 total=3382, TP=1268, TN=1430, FP=261, FN=423; precision=0.829, recall=0.750, Sn=0.750, Sp=0.846\n",
      "roc_auc: (test=0.867) average_precision: (test=0.870) accuracy: (test=0.798) matthews_corrcoef: (test=0.598) f1: (test=0.788) \n",
      "\n",
      "epoch 6 [53/53] total_loss = 0.47442554190473735 lr = 0.0005, total=3382, TP=1278, TN=1385, FP=306, FN=413; precision=0.807, recall=0.756, Sn=0.756, Sp=0.819\n",
      "roc_auc: (test=0.853) average_precision: (test=0.858) accuracy: (test=0.787) matthews_corrcoef: (test=0.576) f1: (test=0.780) \n",
      "epoch 6 [53/53] total_loss = 0.5102054532968773 total=3382, TP=1425, TN=1255, FP=436, FN=266; precision=0.766, recall=0.843, Sn=0.843, Sp=0.742\n",
      "roc_auc: (test=0.869) average_precision: (test=0.872) accuracy: (test=0.792) matthews_corrcoef: (test=0.588) f1: (test=0.802) \n",
      "\n",
      "epoch 7 [53/53] total_loss = 0.47115960998355216 lr = 0.0005, total=3382, TP=1258, TN=1388, FP=303, FN=433; precision=0.806, recall=0.744, Sn=0.744, Sp=0.821\n",
      "roc_auc: (test=0.857) average_precision: (test=0.858) accuracy: (test=0.782) matthews_corrcoef: (test=0.566) f1: (test=0.774) \n",
      "epoch 7 [53/53] total_loss = 0.5153701105770075 total=3382, TP=1455, TN=1170, FP=521, FN=236; precision=0.736, recall=0.860, Sn=0.860, Sp=0.692\n",
      "roc_auc: (test=0.872) average_precision: (test=0.875) accuracy: (test=0.776) matthews_corrcoef: (test=0.560) f1: (test=0.794) \n",
      "\n",
      "epoch 8 [53/53] total_loss = 0.4673921150981255 lr = 0.0005, total=3382, TP=1273, TN=1389, FP=302, FN=418; precision=0.808, recall=0.753, Sn=0.753, Sp=0.821\n",
      "roc_auc: (test=0.859) average_precision: (test=0.861) accuracy: (test=0.787) matthews_corrcoef: (test=0.576) f1: (test=0.780) \n",
      "epoch 8 [53/53] total_loss = 0.4957559367395797 total=3382, TP=1224, TN=1489, FP=202, FN=467; precision=0.858, recall=0.724, Sn=0.724, Sp=0.881\n",
      "roc_auc: (test=0.871) average_precision: (test=0.875) accuracy: (test=0.802) matthews_corrcoef: (test=0.612) f1: (test=0.785) \n",
      "\n",
      "epoch 9 [53/53] total_loss = 0.4630885607791397 lr = 0.0005, total=3382, TP=1296, TN=1396, FP=295, FN=395; precision=0.815, recall=0.766, Sn=0.766, Sp=0.826\n",
      "roc_auc: (test=0.861) average_precision: (test=0.859) accuracy: (test=0.796) matthews_corrcoef: (test=0.593) f1: (test=0.790) \n",
      "epoch 9 [53/53] total_loss = 0.4841495296865139 total=3382, TP=1223, TN=1491, FP=200, FN=468; precision=0.859, recall=0.723, Sn=0.723, Sp=0.882\n",
      "roc_auc: (test=0.873) average_precision: (test=0.876) accuracy: (test=0.802) matthews_corrcoef: (test=0.613) f1: (test=0.785) \n",
      "\n",
      "epoch 10 [53/53] total_loss = 0.4633284222404912 lr = 0.0005, total=3382, TP=1281, TN=1400, FP=291, FN=410; precision=0.815, recall=0.758, Sn=0.758, Sp=0.828\n",
      "roc_auc: (test=0.861) average_precision: (test=0.863) accuracy: (test=0.793) matthews_corrcoef: (test=0.587) f1: (test=0.785) \n",
      "epoch 10 [53/53] total_loss = 0.49284602111240605 total=3382, TP=1314, TN=1412, FP=279, FN=377; precision=0.825, recall=0.777, Sn=0.777, Sp=0.835\n",
      "roc_auc: (test=0.874) average_precision: (test=0.876) accuracy: (test=0.806) matthews_corrcoef: (test=0.613) f1: (test=0.800) \n",
      "\n",
      "epoch 11 [53/53] total_loss = 0.4521032628023399 lr = 0.0005, total=3382, TP=1280, TN=1423, FP=268, FN=411; precision=0.827, recall=0.757, Sn=0.757, Sp=0.842\n",
      "roc_auc: (test=0.869) average_precision: (test=0.871) accuracy: (test=0.799) matthews_corrcoef: (test=0.601) f1: (test=0.790) \n",
      "epoch 11 [53/53] total_loss = 0.4941432161151238 total=3382, TP=1422, TN=1276, FP=415, FN=269; precision=0.774, recall=0.841, Sn=0.841, Sp=0.755\n",
      "roc_auc: (test=0.875) average_precision: (test=0.877) accuracy: (test=0.798) matthews_corrcoef: (test=0.598) f1: (test=0.806) \n",
      "\n",
      "epoch 12 [53/53] total_loss = 0.4493977556813438 lr = 0.0005, total=3382, TP=1292, TN=1414, FP=277, FN=399; precision=0.823, recall=0.764, Sn=0.764, Sp=0.836\n",
      "roc_auc: (test=0.870) average_precision: (test=0.869) accuracy: (test=0.800) matthews_corrcoef: (test=0.602) f1: (test=0.793) \n",
      "epoch 12 [53/53] total_loss = 0.4799842879457294 total=3382, TP=1160, TN=1535, FP=156, FN=531; precision=0.881, recall=0.686, Sn=0.686, Sp=0.908\n",
      "roc_auc: (test=0.876) average_precision: (test=0.880) accuracy: (test=0.797) matthews_corrcoef: (test=0.609) f1: (test=0.772) \n",
      "\n",
      "epoch 13 [53/53] total_loss = 0.4474220647002166 lr = 0.0005, total=3382, TP=1309, TN=1409, FP=282, FN=382; precision=0.823, recall=0.774, Sn=0.774, Sp=0.833\n",
      "roc_auc: (test=0.872) average_precision: (test=0.873) accuracy: (test=0.804) matthews_corrcoef: (test=0.608) f1: (test=0.798) \n",
      "epoch 13 [53/53] total_loss = 0.4871605561589295 total=3382, TP=1098, TN=1563, FP=128, FN=593; precision=0.896, recall=0.649, Sn=0.649, Sp=0.924\n",
      "roc_auc: (test=0.877) average_precision: (test=0.880) accuracy: (test=0.787) matthews_corrcoef: (test=0.597) f1: (test=0.753) \n",
      "\n",
      "epoch 14 [53/53] total_loss = 0.4509055035294227 lr = 0.0005, total=3382, TP=1293, TN=1418, FP=273, FN=398; precision=0.826, recall=0.765, Sn=0.765, Sp=0.839\n",
      "roc_auc: (test=0.867) average_precision: (test=0.872) accuracy: (test=0.802) matthews_corrcoef: (test=0.605) f1: (test=0.794) \n",
      "epoch 14 [53/53] total_loss = 0.47755371090376153 total=3382, TP=1394, TN=1338, FP=353, FN=297; precision=0.798, recall=0.824, Sn=0.824, Sp=0.791\n",
      "roc_auc: (test=0.881) average_precision: (test=0.883) accuracy: (test=0.808) matthews_corrcoef: (test=0.616) f1: (test=0.811) \n",
      "\n",
      "epoch 15 [53/53] total_loss = 0.4566669076118829 lr = 0.0005, total=3382, TP=1304, TN=1409, FP=282, FN=387; precision=0.822, recall=0.771, Sn=0.771, Sp=0.833\n",
      "roc_auc: (test=0.864) average_precision: (test=0.866) accuracy: (test=0.802) matthews_corrcoef: (test=0.606) f1: (test=0.796) \n",
      "epoch 15 [53/53] total_loss = 0.47308577569025867 total=3382, TP=1371, TN=1357, FP=334, FN=320; precision=0.804, recall=0.811, Sn=0.811, Sp=0.802\n",
      "roc_auc: (test=0.880) average_precision: (test=0.884) accuracy: (test=0.807) matthews_corrcoef: (test=0.613) f1: (test=0.807) \n",
      "\n",
      "epoch 16 [53/53] total_loss = 0.44396498124554473 lr = 0.0005, total=3382, TP=1299, TN=1434, FP=257, FN=392; precision=0.835, recall=0.768, Sn=0.768, Sp=0.848\n",
      "roc_auc: (test=0.873) average_precision: (test=0.874) accuracy: (test=0.808) matthews_corrcoef: (test=0.618) f1: (test=0.800) \n",
      "epoch 16 [53/53] total_loss = 0.4698489297111079 total=3382, TP=1305, TN=1444, FP=247, FN=386; precision=0.841, recall=0.772, Sn=0.772, Sp=0.854\n",
      "roc_auc: (test=0.881) average_precision: (test=0.885) accuracy: (test=0.813) matthews_corrcoef: (test=0.628) f1: (test=0.805) \n",
      "\n",
      "epoch 17 [53/53] total_loss = 0.448371540263014 lr = 0.0005, total=3382, TP=1297, TN=1433, FP=258, FN=394; precision=0.834, recall=0.767, Sn=0.767, Sp=0.847\n",
      "roc_auc: (test=0.871) average_precision: (test=0.868) accuracy: (test=0.807) matthews_corrcoef: (test=0.616) f1: (test=0.799) \n",
      "epoch 17 [53/53] total_loss = 0.4751370684155878 total=3382, TP=1429, TN=1264, FP=427, FN=262; precision=0.770, recall=0.845, Sn=0.845, Sp=0.747\n",
      "roc_auc: (test=0.882) average_precision: (test=0.886) accuracy: (test=0.796) matthews_corrcoef: (test=0.595) f1: (test=0.806) \n",
      "\n",
      "epoch 18 [53/53] total_loss = 0.43394783813998383 lr = 0.0005, total=3382, TP=1316, TN=1425, FP=266, FN=375; precision=0.832, recall=0.778, Sn=0.778, Sp=0.843\n",
      "roc_auc: (test=0.879) average_precision: (test=0.883) accuracy: (test=0.810) matthews_corrcoef: (test=0.622) f1: (test=0.804) \n",
      "epoch 18 [53/53] total_loss = 0.48070127615388836 total=3382, TP=1474, TN=1213, FP=478, FN=217; precision=0.755, recall=0.872, Sn=0.872, Sp=0.717\n",
      "roc_auc: (test=0.884) average_precision: (test=0.888) accuracy: (test=0.795) matthews_corrcoef: (test=0.596) f1: (test=0.809) \n",
      "\n",
      "epoch 19 [53/53] total_loss = 0.4362290327279073 lr = 0.0005, total=3382, TP=1316, TN=1424, FP=267, FN=375; precision=0.831, recall=0.778, Sn=0.778, Sp=0.842\n",
      "roc_auc: (test=0.879) average_precision: (test=0.878) accuracy: (test=0.810) matthews_corrcoef: (test=0.622) f1: (test=0.804) \n",
      "epoch 19 [53/53] total_loss = 0.45520575991216694 total=3382, TP=1324, TN=1444, FP=247, FN=367; precision=0.843, recall=0.783, Sn=0.783, Sp=0.854\n",
      "roc_auc: (test=0.884) average_precision: (test=0.889) accuracy: (test=0.818) matthews_corrcoef: (test=0.639) f1: (test=0.812) \n",
      "\n",
      "epoch 20 [53/53] total_loss = 0.43458171723023903 lr = 0.0005, total=3382, TP=1313, TN=1421, FP=270, FN=378; precision=0.829, recall=0.776, Sn=0.776, Sp=0.840\n",
      "roc_auc: (test=0.880) average_precision: (test=0.882) accuracy: (test=0.808) matthews_corrcoef: (test=0.618) f1: (test=0.802) \n",
      "epoch 20 [53/53] total_loss = 0.45341202110614415 total=3382, TP=1319, TN=1442, FP=249, FN=372; precision=0.841, recall=0.780, Sn=0.780, Sp=0.853\n",
      "roc_auc: (test=0.883) average_precision: (test=0.888) accuracy: (test=0.816) matthews_corrcoef: (test=0.634) f1: (test=0.809) \n",
      "\n",
      "epoch 21 [53/53] total_loss = 0.426861213625602 lr = 0.0005, total=3382, TP=1314, TN=1431, FP=260, FN=377; precision=0.835, recall=0.777, Sn=0.777, Sp=0.846\n",
      "roc_auc: (test=0.883) average_precision: (test=0.887) accuracy: (test=0.812) matthews_corrcoef: (test=0.625) f1: (test=0.805) \n",
      "epoch 21 [53/53] total_loss = 0.44982185847354383 total=3382, TP=1310, TN=1458, FP=233, FN=381; precision=0.849, recall=0.775, Sn=0.775, Sp=0.862\n",
      "roc_auc: (test=0.886) average_precision: (test=0.890) accuracy: (test=0.818) matthews_corrcoef: (test=0.639) f1: (test=0.810) \n",
      "\n",
      "epoch 22 [53/53] total_loss = 0.433302067923096 lr = 0.0005, total=3382, TP=1310, TN=1428, FP=263, FN=381; precision=0.833, recall=0.775, Sn=0.775, Sp=0.844\n",
      "roc_auc: (test=0.880) average_precision: (test=0.882) accuracy: (test=0.810) matthews_corrcoef: (test=0.621) f1: (test=0.803) \n",
      "epoch 22 [53/53] total_loss = 0.5118262419160807 total=3382, TP=1539, TN=1031, FP=660, FN=152; precision=0.700, recall=0.910, Sn=0.910, Sp=0.610\n",
      "roc_auc: (test=0.885) average_precision: (test=0.890) accuracy: (test=0.760) matthews_corrcoef: (test=0.545) f1: (test=0.791) \n",
      "\n",
      "epoch 23 [53/53] total_loss = 0.4309197816084016 lr = 0.0005, total=3382, TP=1314, TN=1434, FP=257, FN=377; precision=0.836, recall=0.777, Sn=0.777, Sp=0.848\n",
      "roc_auc: (test=0.881) average_precision: (test=0.882) accuracy: (test=0.813) matthews_corrcoef: (test=0.627) f1: (test=0.806) \n",
      "epoch 23 [53/53] total_loss = 0.46040991876485216 total=3382, TP=1445, TN=1288, FP=403, FN=246; precision=0.782, recall=0.855, Sn=0.855, Sp=0.762\n",
      "roc_auc: (test=0.886) average_precision: (test=0.891) accuracy: (test=0.808) matthews_corrcoef: (test=0.619) f1: (test=0.817) \n",
      "\n",
      "epoch 24 [53/53] total_loss = 0.4263779009288212 lr = 0.0005, total=3382, TP=1331, TN=1417, FP=274, FN=360; precision=0.829, recall=0.787, Sn=0.787, Sp=0.838\n",
      "roc_auc: (test=0.884) average_precision: (test=0.888) accuracy: (test=0.813) matthews_corrcoef: (test=0.626) f1: (test=0.808) \n",
      "epoch 24 [53/53] total_loss = 0.448702021589819 total=3382, TP=1271, TN=1478, FP=213, FN=420; precision=0.856, recall=0.752, Sn=0.752, Sp=0.874\n",
      "roc_auc: (test=0.885) average_precision: (test=0.890) accuracy: (test=0.813) matthews_corrcoef: (test=0.630) f1: (test=0.801) \n",
      "\n",
      "epoch 25 [53/53] total_loss = 0.4243332529967686 lr = 0.0005, total=3382, TP=1322, TN=1427, FP=264, FN=369; precision=0.834, recall=0.782, Sn=0.782, Sp=0.844\n",
      "roc_auc: (test=0.886) average_precision: (test=0.889) accuracy: (test=0.813) matthews_corrcoef: (test=0.627) f1: (test=0.807) \n",
      "epoch 25 [53/53] total_loss = 0.44621951793724635 total=3382, TP=1401, TN=1347, FP=344, FN=290; precision=0.803, recall=0.829, Sn=0.829, Sp=0.797\n",
      "roc_auc: (test=0.887) average_precision: (test=0.892) accuracy: (test=0.813) matthews_corrcoef: (test=0.625) f1: (test=0.815) \n",
      "\n",
      "『TRAIN__TEST OVER!!!』\n",
      ">>>>>>>>>>『CV END』[2/1]>>>>>>>>>>>>\n",
      " \n",
      "『Computer device』nvidia:ProL\n",
      "『dataset』kmer: 2, cv: 2\n",
      "『train config』epochs: 25, lr: 0.0005, batch_size: 64, device: cuda\n",
      "『pre-model config [True]』add_special_tokens: False, not_fine_tuning: True, model_name: longformer-base-4096\n",
      "『ex result config』ex_result_dir: d:\\Project\\DNA\\iProL\\src\\../result/longformer/_train[kmer2_bs64_lr0.0005_epoch25]_pm[astFalse_nftTrue_levelbase]\\ProL_1216232630_Pro\n",
      "『Score Saving』Score Saved!!!\n",
      "Ex result dir d:\\Project\\DNA\\iProL\\src\\../result/longformer/_train[kmer2_bs64_lr0.0005_epoch25]_pm[astFalse_nftTrue_levelbase]\\ProL_1216232630_Pro\\2 has been created!\n",
      ">>>>>>>>>>『CV START』[2/2-->lr:[0.0005]]>>>>>>>>>>>>\n",
      ">>>>>>>>>>『CV START』[2/2]>>>>>>>>>>>>\n",
      "『Computer device』nvidia:ProL\n",
      "『dataset』kmer: 2, cv: 2\n",
      "『train config』epochs: 25, lr: 0.0005, batch_size: 64, device: cuda\n",
      "『pre-model config [True]』add_special_tokens: False, not_fine_tuning: True, model_name: longformer-base-4096\n",
      "『ex result config』ex_result_dir: d:\\Project\\DNA\\iProL\\src\\../result/longformer/_train[kmer2_bs64_lr0.0005_epoch25]_pm[astFalse_nftTrue_levelbase]\\ProL_1216232630_Pro\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \u001b[32m50\u001b[39m, gamma=\u001b[32m0.6\u001b[39m)\n\u001b[32m     35\u001b[39m criterion = nn.BCELoss()\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mmodel_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.86\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\DNA\\iProL\\src\\tools_fit.py:89\u001b[39m, in \u001b[36mmodel_fit\u001b[39m\u001b[34m(config, model, train_loader, test_loader, optimizer, criterion, scheduler, threshold, cv_idx)\u001b[39m\n\u001b[32m     87\u001b[39m check_result_dir(config, cv_idx=cv_idx)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, config.epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     train_loss_epoch, train_score_dict = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m scheduler:\n\u001b[32m     91\u001b[39m         lr_list.append(scheduler.get_lr()[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\DNA\\iProL\\src\\tools_fit.py:12\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(epoch, model, train_loader, optimizer, criterion, scheduler, device)\u001b[39m\n\u001b[32m     10\u001b[39m y_train = []\n\u001b[32m     11\u001b[39m y_prob_train = []\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx_train, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     14\u001b[39m         X = X.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:494\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:427\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1172\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1165\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1171\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1172\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1174\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\context.py:337\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\popen_spawn_win32.py:97\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     96\u001b[39m     reduction.dump(prep_data, to_child)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     99\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "识别promoter：Pro\n",
    "\"\"\"\n",
    "for cv_idx, (train_loader, test_loader) in enumerate(identify_loader_list, 1):\n",
    "    check_result_dir(config, cv_idx)\n",
    "    # model = Longformer_base_lstm_Net(config.model_name, config.device,\n",
    "    #                                  config.add_special_tokens,\n",
    "    #                                  bidirectional=config.bidirectional,\n",
    "    #                                  num_layers=config.num_layers)\n",
    "    \"\"\"去掉一个CNN，dense1参数 in_channels进入\"\"\"\n",
    "    # model = Longformer_base_2cnn_lstm_Net(config.model_name, config.device,\n",
    "    #                                  config.add_special_tokens,\n",
    "    #                                  bidirectional=config.bidirectional,\n",
    "    #                                  num_layers=config.num_layers)\n",
    "    \"\"\"Longformer_base_lstm_BNpos_Net: 修改BN到pooling之后dropout之前， 美纱用\"\"\"\n",
    "    # model = Longformer_base_lstm_BNpos_Net(config.model_name, config.device,\n",
    "    #                                  config.add_special_tokens,\n",
    "    #                                  bidirectional=config.bidirectional,\n",
    "    #                                  num_layers=config.num_layers)\n",
    "    \"\"\"\n",
    "    没有LSTM\n",
    "    \"\"\"\n",
    "    model = Longformer_base_Net(config.model_name, config.device,\n",
    "                                     config.add_special_tokens)\n",
    "    model.to(config.device)\n",
    "\n",
    "    # 这里是一般情况，共享层往往不止一层，所以做一个for循环\n",
    "    if hasattr(model, 'longformer') and config.not_fine_tuning:\n",
    "        for para in model.longformer.parameters():\n",
    "            para.requires_grad = False\n",
    "        # print(module.parameters())\n",
    "\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 50, gamma=0.6)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    model_fit(config, model, train_loader, test_loader, optimizer, criterion, scheduler, 0.86, cv_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "『now_time』:1216230130\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "now_time = time.strftime('%m%d%H%M%S', time.localtime())\n",
    "print(f\"『now_time』:{now_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
